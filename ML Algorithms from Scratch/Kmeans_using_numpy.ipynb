{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means steps:\n",
    "# 1. initialize:\n",
    "# - k = number of clusers\n",
    "# - Data = Data to cluster\n",
    "# - iterations - no. of iterations\n",
    "\n",
    "# 2. repeat:\n",
    "# - initiate k random centroids from data\n",
    "# - calculate euclidiean distance b/w each data point and centroids and assign that data point to centroid/cluster with minimum distance\n",
    "# - calculate new centroid - mean of all datapoints\n",
    "# - untill old centroid == new centroid or no. of iterations\n",
    "\n",
    "# 3. Output:\n",
    "# - final k clusters and their corresponding centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(self, clusters):\n",
    "    n_labels = np.empty(self.n_samples)\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for sample_idx in cluster:\n",
    "            n_labels[sample_idx] = i\n",
    "\n",
    "    return n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=gnGyTRFLX-k\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, k=3, iterations=2000):\n",
    "        self.k = k\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def euclideanDistance(self, v1, v2):\n",
    "        return np.sqrt(np.sum((v1-v2)**2))\n",
    "\n",
    "    def createClusters(self, centroids):\n",
    "        clusters = [[] for _ in range(self.k)]\n",
    "        for i, samples in enumerate(self.X):\n",
    "            distances = [self.euclideanDistance(samples, c) for c in centroids]\n",
    "            cluster_idx = np.argmin(distances)\n",
    "            clusters[cluster_idx].append(i)\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def getNewCentroid(self, clusters):\n",
    "        new_centroids = np.zeros((self.k, self.n_features), dtype=np.float64)\n",
    "        for i, c in enumerate(clusters):\n",
    "            cluster_mean = np.mean(self.X[c], axis=0)\n",
    "            new_centroids[i] = cluster_mean\n",
    "\n",
    "        return new_centroids\n",
    "\n",
    "    def isConverged(self, old_centroids, new_centroids):\n",
    "        distance = [self.euclideanDistance(old_centroids[i], new_centroids[i]) for i in range(self.k)]\n",
    "        return np.sum(distance) == 0\n",
    "\n",
    "    def getLabels(self, clusters):\n",
    "        n_labels = np.empty(self.n_samples)\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            for sample in cluster:\n",
    "                n_labels[sample] = i\n",
    "\n",
    "        return n_labels\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        rand_idx = np.random.choice(self.n_samples, self.k, replace=False)\n",
    "        centroids = [self.X[i] for i in rand_idx]\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            clusters = self.createClusters(centroids)\n",
    "            old_centroids = centroids\n",
    "            centroids = self.getNewCentroid(clusters)\n",
    "\n",
    "            if self.isConverged(old_centroids, centroids):\n",
    "                break\n",
    "\n",
    "        return self.getLabels(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ds.make_blobs(n_samples=150, n_features=2, centers=3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true==y_pred)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "y_pred = kmeans.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.35)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Here are some ways to optimize the k-means clustering algorithm:\n",
    "\n",
    "Random initialization of centroids: Instead of initializing the centroids using the first k data points, we can randomly initialize them to improve the convergence of the algorithm. This can be done by selecting k random data points from the input dataset as the initial centroids.\n",
    "\n",
    "Early stopping: We can stop the k-means algorithm if the cluster assignments and centroids do not change after a certain number of iterations. This helps to avoid unnecessary computation.\n",
    "\n",
    "Vectorization: We can use numpy arrays and vectorized operations to speed up the computation. This avoids the need for loops and makes the code more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
